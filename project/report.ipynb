{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Report\n",
    "This Data Engineering project analyzes the correlation between the frequency of checks conducted on air transport of dangerous goods and the number of accidents that occur. The insights gained from this project can inform policy decisions and resource allocation in the transportation industry.\n",
    "\n",
    "## Agenda\n",
    "1. [Dataset](#Dataset)\n",
    "2. [Data Pipeline](#Data-Pipeline)\n",
    "    * Preperation\n",
    "    * Extract Data\n",
    "    * Transform Data\n",
    "    * Load Data into SQL\n",
    "3. [Exploratory Analysis](#Exp) \n",
    "    * Key Figures\n",
    "    * Graphs\n",
    "4. [Conclusion from Data](#conc)\n",
    "5. [Implications](#Imp)\n",
    "\n",
    "<a id='Dataset'></a>\n",
    "\n",
    "## 1.Dataset\n",
    "Two data sets exist, both of which relate to dangerous goods in air traffic.\n",
    "Dataset 1:\n",
    "Refers to dangerous goods checks per year in Germany. A distinction is made between German air carriers/Foreign air carriers/Handling Agents/German airports and aerodromes/Express Courier with own aeroplanes.\n",
    "Dataset 2:\n",
    "Refers to incidents and acccidents with dangerous goods per year in Germany. A distinction is made between Incidents&Acccidents/Accidents with injuries to persons/Administrative offense proceedings/Applications for exemptions/Permissions for overflight/Approvals for the transport of Dangerous/Goods for German air carriers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 2.Data Pipeline\n",
    "<a id='Data-Pipeline'></a>\n",
    "## Code Description\n",
    "\n",
    "This task was done in \"/data/data_pipeline.py\"\n",
    "The given code represents a data pipeline that performs several tasks to process and store data. Here is a description of the code in words:\n",
    "\n",
    "### Preperation\n",
    "1. Import the necessary libraries:\n",
    "\n",
    "The code begins by installing and importing the necessary libraries, sqlite3 for database operations and pandas for data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\python311\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\python311\\lib\\site-packages (from pandas) (1.25.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openpyxl in c:\\python311\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\python311\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import sqlite3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data\n",
    "2. Load Excel files:\n",
    "\n",
    "Two Excel files are loaded using the pd.read_excel() function. These files contain data related to 'Gefahrgutkontrollen' (hazard controls) and 'Gefahrgutzwischenfaelle' (hazard incidents) respectively, and they are fetched from online sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('https://www.lba.de/SharedDocs/Downloads/DE/SBl/SBl3/Statistiken/Betrieb/Gefahrgutkontrollen.xlsx?__blob=publicationFile&v=5', engine='openpyxl')\n",
    "df2 = pd.read_excel('https://www.lba.de/SharedDocs/Downloads/DE/SBl/SBl3/Statistiken/Betrieb/Gefahrgutzwischenfaelle.xlsx?__blob=publicationFile&v=5', engine='openpyxl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Data\n",
    "\n",
    "3. Specify rows to delete for each DataFrame and drop them:\n",
    "\n",
    "The code specifies the rows to be deleted for each DataFrame using the rows_to_delete1 and rows_to_delete2 lists.\n",
    "Rows are deleted from both DataFrames using the drop() method with inplace=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_delete1 = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "rows_to_delete2 = [0, 1, 2, 3, 4, 5, 6, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75]\n",
    "\n",
    "df1.drop(rows_to_delete1, inplace=True)\n",
    "df2.drop(rows_to_delete2, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Modify column names:\n",
    "\n",
    "The column names of both DataFrames are modified by assigning new names using the columns attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names1 = ['Year', 'German air carriers', 'Foreign air carriers','Handling Agents', 'German Airports and Aerodromes','Express Courier with own aeroplanes'] \n",
    "df1.columns = column_names1\n",
    "\n",
    "column_names2 = ['Year','Incidents/Accidents','Accidents with injuries to persons','administrative offense proceedings','Applications for exemptions','Permissions for overflight','Approvals for the transport of Dangerous Goods for German air carriers']\n",
    "df2.columns = column_names2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Set 'Year' as the index for both DataFrames:\n",
    "\n",
    "The 'Year' column is set as the index for both DataFrames using the set_index() method. As an example the table df1 is printed to show the result of the data tranformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     German air carriers Foreign air carriers Handling Agents  \\\n",
      "Year                                                            \n",
      "2000                   2                   16              42   \n",
      "2001                  15                    8              28   \n",
      "2002                  22                   16              39   \n",
      "2003                  46                   24              23   \n",
      "2004                  56                   35              39   \n",
      "2005                  54                   38              78   \n",
      "2006                  44                   14              54   \n",
      "2007                  36                   16              58   \n",
      "2008                  40                   20              63   \n",
      "2009                  19                   18              75   \n",
      "2010                  29                   14              87   \n",
      "2011                  19                    5             103   \n",
      "2012                  30                   21             108   \n",
      "2013                  31                   10              97   \n",
      "2014                  36                    9              95   \n",
      "2015                  22                    7              74   \n",
      "2016                  45                   77              62   \n",
      "2017                 116                   69              87   \n",
      "2018                  48                   54              83   \n",
      "2019                  72                   12              69   \n",
      "2020                  53                    2              11   \n",
      "2021                  21                    1               3   \n",
      "2022                  52                    0               1   \n",
      "\n",
      "     German Airports and Aerodromes Express Courier with own aeroplanes  \n",
      "Year                                                                     \n",
      "2000                             14                                   2  \n",
      "2001                             10                                   1  \n",
      "2002                             16                                   0  \n",
      "2003                             13                                   1  \n",
      "2004                             20                                   1  \n",
      "2005                             22                                   1  \n",
      "2006                             14                                   2  \n",
      "2007                             11                                   2  \n",
      "2008                             18                                   2  \n",
      "2009                             23                                   1  \n",
      "2010                             31                                   2  \n",
      "2011                             20                                   0  \n",
      "2012                             23                                   2  \n",
      "2013                             27                                   1  \n",
      "2014                             17                                   2  \n",
      "2015                             13                                   4  \n",
      "2016                             15                                   1  \n",
      "2017                             13                                   3  \n",
      "2018                             15                                   1  \n",
      "2019                             10                                   1  \n",
      "2020                              2                                   0  \n",
      "2021                              3                                   0  \n",
      "2022                              1                                   0  \n"
     ]
    }
   ],
   "source": [
    "df1= df1.set_index('Year')\n",
    "df2= df2.set_index('Year')\n",
    "\n",
    "print(df1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data into SQL\n",
    "\n",
    "6. Write DataFrames to SQLite tables:\n",
    "\n",
    "A connection to an SQLite database is established using sqlite3.connect() by providing the path to the database file.\n",
    "\n",
    "The DataFrames are written to separate tables in the SQLite database using the to_sql() method. If the tables already exist, the if_exists=\"replace\" parameter ensures they are replaced with the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (3231306683.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[23], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    conn = sqlite3.connect('C:\\Users\\magis\\OneDrive\\Desktop\\data engineering\\2023-amse-template_magnus\\data\\database.db')\u001b[0m\n\u001b[1;37m                                                                                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('C:\\Users\\magis\\OneDrive\\Desktop\\data engineering\\2023-amse-template_magnus\\data\\database.db')\n",
    "\n",
    "df1.to_sql('Gefahrenkontrollen', conn, if_exists=\"replace\")\n",
    "df2.to_sql('Gefahrgutzwischenfaelle', conn, if_exists=\"replace\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
